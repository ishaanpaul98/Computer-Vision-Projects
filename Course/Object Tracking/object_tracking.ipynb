{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movement casued by the movement of the object or camera.\n",
    "\n",
    "It has a few assumptions:\n",
    "* The pixel intensitites of an object do not change between consecutive frames.\n",
    "* Neighbouring pixels have similar motion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optical flow methods in OpenCV will first taken in a givens set of points from the user. The method will then attempt to find those points in the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV uses the Lucas-Kanade function. It computes optical flow for a sparse feature set (Only tracks the points that it was told to track). If we want to track all the points, wecan use the Gunner Farneback's algorithm to calculate dense optical flow. It colors the image black if no flow is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucas-Kanade Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_track_params = dict(maxCorners = 10, qualityLevel = 0.3, minDistance = 7, blockSize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk_params = dict(winSize = (200,200), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Points to track\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask=None, **corner_track_params)\n",
    "#Creates a mask of size of the previous frame\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "        x_new, y_new = new.ravel()\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "        \n",
    "        mask = cv2.line(mask, (int(x_new), int(y_new)), (int(x_prev), int(y_prev)), (0,255,0), 3)\n",
    "\n",
    "        frame = cv2.circle(frame, (int(x_new), int(y_new)), 8, (0,0,255), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow('tracking', img)\n",
    "\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "prevImg = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_mask = np.zeros_like(frame1)\n",
    "\n",
    "hsv_mask[:,:,1] = 255\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    nextImg = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prevImg, nextImg, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    #Convert to polar coordinates\n",
    "    mag, ang = cv2.cartToPolar(flow[:, :, 0], flow[:, :, 1], angleInDegrees=True)\n",
    "\n",
    "    hsv_mask[:, :, 0] = ang/2\n",
    "\n",
    "    hsv_mask[:, :, 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    bgr = cv2.cvtColor(hsv_mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    cv2.imshow('frame', bgr)\n",
    "\n",
    "    k = cv2.waitKey(10) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    prevImg = nextImg\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanShift and CamShift Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets all points into clusters and get the points to cluster towards their respective centers every iteration until all clusters have converged and there is no more movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeanShift can be given a target to track, calculate the color histogram of the target area, and then keep sliding the tracking window to the closest match (Cluster center)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('Images/haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_rects = face_cascade.detectMultiScale(frame)\n",
    "\n",
    "(face_x, face_y, w, h) = tuple(face_rects[0])\n",
    "\n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "roi = frame[face_y:face_y+h, face_x:face_x+w]\n",
    "\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0,180], 1)\n",
    "\n",
    "        #ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame, [pts], True, (0,0,255), 3)\n",
    "\n",
    "\n",
    "        #x, y, w, h = track_window\n",
    "        #img2 = cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255), 5)\n",
    "\n",
    "        cv2.imshow('img', img2)\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xFF \n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break      \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
